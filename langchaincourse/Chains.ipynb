{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34c8954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "#memory and conversation\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "#chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnableMap\n",
    "#prompts\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8528a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a name to describe a company that makes\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46d03699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chain combines LLM with a prompt and carry out a sequence of operations on text and data\n",
    "\n",
    "#import data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be1c3cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'Queen Size Sheet Set', 'text': \"Of course! Could you please provide more details about the company's products or services?\"}\n"
     ]
    }
   ],
   "source": [
    "#create a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "product = \"Queen Size Sheet Set\"\n",
    "\n",
    "\n",
    "# Use `invoke` instead of `run`\n",
    "response = chain.invoke({\"product\": product})\n",
    "\n",
    "# Print the result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a079a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19d556c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1646e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b9f2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2bf87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing a name for a company that specializes in Queen Size Sheet Sets involves considering factors like brand identity, target audience, and market positioning. Here are a few suggestions:\n",
      "\n",
      "1. **Queen's Comfort**\n",
      "2. **Royal Rest Linens**\n",
      "3. **Majestic Sheets**\n",
      "4. **Sovereign Sleep**\n",
      "5. **Elegance Bedding**\n",
      "6. **Regal Sleepwear**\n",
      "7. **Queen's Haven**\n",
      "8. **Dreamy Drapes**\n",
      "9. **Noble Night Linens**\n",
      "10. **Crown Comforts**\n",
      "\n",
      "When choosing a name, it's important to ensure that it's unique, easy to remember, and can be easily associated with the products you are offering. Additionally, checking for domain availability for a matching website can be beneficial.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Premium supplier of luxurious queen-size sheet sets, blending comfort and elegance for a regal sleeping experience. Perfect for discerning customers.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Premium supplier of luxurious queen-size sheet sets, blending comfort and elegance for a regal sleeping experience. Perfect for discerning customers.\"'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed0b44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SEQUENTIAL CHAIN\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n",
    "\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71c6b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c57eb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': 'The reviewer is dissatisfied with the taste and quality of the product compared to store-bought versions, suspecting it might be from an old batch or counterfeit.',\n",
       " 'followup_message': \"Cher(e) [Nom du client],\\n\\nMerci d'avoir partagé votre retour d'expérience concernant notre produit. Nous sommes désolés d'apprendre que le goût et la qualité n'ont pas répondu à vos attentes. Sachez que nous prenons très au sérieux les préoccupations de nos clients. Nous nous engageons à n'utiliser que des ingrédients de haute qualité et à respecter des normes de production rigoureuses. Il est possible qu'il s'agisse d'un lot défectueux ou d'un problème isolé, et nous aimerions en savoir plus pour résoudre cette situation.\\n\\nPourriez-vous nous fournir le numéro de lot ou toute autre information pertinente figurant sur l'emballage ? Cela nous aidera à enquêter plus précisément sur la question. En attendant, nous serions heureux de vous offrir un remplacement ou un remboursement, selon votre préférence.\\n\\nNous vous remercions de nous avoir alertés et espérons regagner votre confiance bientôt.\\n\\nCordialement,\\n\\n[Votre nom]\\nService Clientèle\"}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31d05ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROUTER CHAIN\n",
    "\n",
    "physics_template = \"\"\"The answer is physics. Respond back \"physics\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"The answer is math. Respond back \"math\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"The answer is history. Respond back \"history\" do note write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" The answer is \"comp sci\". Respond back \"comp sci\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ce72fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "67dd9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination chains dynamically\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    prompt_template = ChatPromptTemplate.from_template(template=p_info[\"prompt_template\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    destination_chains[p_info[\"name\"]] = chain\n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "\n",
    "#default destination chain\n",
    "default_prompt = ChatPromptTemplate.from_template(\"I am not sure how to answer this: {input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c52728e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b176a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e2d70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# Use LLM to execute the router prompt\n",
    "router_chain = LLMChain(llm=llm, prompt=router_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "69dfd361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"destination\": \"physics\",\n",
      "    \"next_inputs\": \"Tell me about Newton's laws of motion.\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"math\",\n",
      "    \"next_inputs\": \"What is 2 + 2?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"history\",\n",
      "    \"next_inputs\": \"Explain the Industrial Revolution.\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"computer science\",\n",
      "    \"next_inputs\": \"What is a Turing machine?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"DEFAULT\",\n",
      "    \"next_inputs\": \"What is the weather like today?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example Inputs\n",
    "example_inputs = [\n",
    "    {\"input\": \"Tell me about Newton's laws of motion.\"},\n",
    "    {\"input\": \"What is 2 + 2?\"},\n",
    "    {\"input\": \"Explain the Industrial Revolution.\"},\n",
    "    {\"input\": \"What is a Turing machine?\"},\n",
    "    {\"input\": \"What is the weather like today?\"},  # To test the default chain\n",
    "]\n",
    "\n",
    "for user_input in example_inputs:\n",
    "    print(router_chain.predict(input=user_input))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f40db3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Tell me about Newton's laws of motion.\n",
      "Response: Physics.\n",
      "--------------------------------------------------\n",
      "Input: What is 2 + 2?\n",
      "Response: math\n",
      "--------------------------------------------------\n",
      "Input: Explain the Industrial Revolution.\n",
      "Response: History.\n",
      "--------------------------------------------------\n",
      "Input: What is a Turing machine?\n",
      "Response: comp sci\n",
      "--------------------------------------------------\n",
      "Input: What is the weather like today?\n",
      "Response: I'm sorry, but I can't provide real-time weather updates or information. Please check a reliable weather website or app for the current conditions in your area.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parse the router result and run the appropriate chain\n",
    "def execute_chain(input_text):\n",
    "    # Get the destination and modified input from the router\n",
    "    router_result = router_chain.predict(input=input_text)\n",
    "    parsed_result = RouterOutputParser().parse(router_result)\n",
    "    destination = parsed_result[\"destination\"]\n",
    "    next_inputs = parsed_result[\"next_inputs\"]\n",
    "\n",
    "    # If destination is in destination_chains, run that chain\n",
    "    if destination in destination_chains:\n",
    "        response = destination_chains[destination].predict(input=next_inputs)\n",
    "    else:  # Fallback to default chain\n",
    "        response = default_chain.predict(input=next_inputs)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example Usage\n",
    "example_inputs = [\n",
    "    \"Tell me about Newton's laws of motion.\",\n",
    "    \"What is 2 + 2?\",\n",
    "    \"Explain the Industrial Revolution.\",\n",
    "    \"What is a Turing machine?\",\n",
    "    \"What is the weather like today?\"  # Should fallback to default\n",
    "]\n",
    "\n",
    "for input_text in example_inputs:\n",
    "    response = execute_chain(input_text)\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7c3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mystudyenv",
   "language": "python",
   "name": "mystudyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
