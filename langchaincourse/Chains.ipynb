{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34c8954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "#memory and conversation\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "#chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnableMap\n",
    "#prompts\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8528a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a name to describe a company that makes\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46d03699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chain combines LLM with a prompt and carry out a sequence of operations on text and data\n",
    "\n",
    "#import data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be1c3cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'Queen Size Sheet Set', 'text': \"Of course! Could you please provide more details about the company's products or services?\"}\n"
     ]
    }
   ],
   "source": [
    "#create a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "product = \"Queen Size Sheet Set\"\n",
    "\n",
    "\n",
    "# Use `invoke` instead of `run`\n",
    "response = chain.invoke({\"product\": product})\n",
    "\n",
    "# Print the result\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a079a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19d556c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1646e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b9f2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2bf87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing a name for a company that specializes in Queen Size Sheet Sets involves considering factors like brand identity, target audience, and market positioning. Here are a few suggestions:\n",
      "\n",
      "1. **Queen's Comfort**\n",
      "2. **Royal Rest Linens**\n",
      "3. **Majestic Sheets**\n",
      "4. **Sovereign Sleep**\n",
      "5. **Elegance Bedding**\n",
      "6. **Regal Sleepwear**\n",
      "7. **Queen's Haven**\n",
      "8. **Dreamy Drapes**\n",
      "9. **Noble Night Linens**\n",
      "10. **Crown Comforts**\n",
      "\n",
      "When choosing a name, it's important to ensure that it's unique, easy to remember, and can be easily associated with the products you are offering. Additionally, checking for domain availability for a matching website can be beneficial.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Premium supplier of luxurious queen-size sheet sets, blending comfort and elegance for a regal sleeping experience. Perfect for discerning customers.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Premium supplier of luxurious queen-size sheet sets, blending comfort and elegance for a regal sleeping experience. Perfect for discerning customers.\"'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed0b44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SEQUENTIAL CHAIN\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n",
    "\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71c6b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c57eb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': 'The reviewer is dissatisfied with the taste and quality of the product compared to store-bought versions, suspecting it might be from an old batch or counterfeit.',\n",
       " 'followup_message': \"Cher(e) [Nom du client],\\n\\nMerci d'avoir partagÃ© votre retour d'expÃ©rience concernant notre produit. Nous sommes dÃ©solÃ©s d'apprendre que le goÃ»t et la qualitÃ© n'ont pas rÃ©pondu Ã  vos attentes. Sachez que nous prenons trÃ¨s au sÃ©rieux les prÃ©occupations de nos clients. Nous nous engageons Ã  n'utiliser que des ingrÃ©dients de haute qualitÃ© et Ã  respecter des normes de production rigoureuses. Il est possible qu'il s'agisse d'un lot dÃ©fectueux ou d'un problÃ¨me isolÃ©, et nous aimerions en savoir plus pour rÃ©soudre cette situation.\\n\\nPourriez-vous nous fournir le numÃ©ro de lot ou toute autre information pertinente figurant sur l'emballage ? Cela nous aidera Ã  enquÃªter plus prÃ©cisÃ©ment sur la question. En attendant, nous serions heureux de vous offrir un remplacement ou un remboursement, selon votre prÃ©fÃ©rence.\\n\\nNous vous remercions de nous avoir alertÃ©s et espÃ©rons regagner votre confiance bientÃ´t.\\n\\nCordialement,\\n\\n[Votre nom]\\nService ClientÃ¨le\"}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31d05ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROUTER CHAIN\n",
    "\n",
    "physics_template = \"\"\"The answer is physics. Respond back \"physics\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"The answer is math. Respond back \"math\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"The answer is history. Respond back \"history\" do note write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" The answer is \"comp sci\". Respond back \"comp sci\" do not write more.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ce72fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "67dd9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination chains dynamically\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    prompt_template = ChatPromptTemplate.from_template(template=p_info[\"prompt_template\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    destination_chains[p_info[\"name\"]] = chain\n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "\n",
    "#default destination chain\n",
    "default_prompt = ChatPromptTemplate.from_template(\"I am not sure how to answer this: {input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c52728e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b176a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e2d70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# Use LLM to execute the router prompt\n",
    "router_chain = LLMChain(llm=llm, prompt=router_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "69dfd361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"destination\": \"physics\",\n",
      "    \"next_inputs\": \"Tell me about Newton's laws of motion.\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"math\",\n",
      "    \"next_inputs\": \"What is 2 + 2?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"history\",\n",
      "    \"next_inputs\": \"Explain the Industrial Revolution.\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"computer science\",\n",
      "    \"next_inputs\": \"What is a Turing machine?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"DEFAULT\",\n",
      "    \"next_inputs\": \"What is the weather like today?\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example Inputs\n",
    "example_inputs = [\n",
    "    {\"input\": \"Tell me about Newton's laws of motion.\"},\n",
    "    {\"input\": \"What is 2 + 2?\"},\n",
    "    {\"input\": \"Explain the Industrial Revolution.\"},\n",
    "    {\"input\": \"What is a Turing machine?\"},\n",
    "    {\"input\": \"What is the weather like today?\"},  # To test the default chain\n",
    "]\n",
    "\n",
    "for user_input in example_inputs:\n",
    "    print(router_chain.predict(input=user_input))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f40db3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Tell me about Newton's laws of motion.\n",
      "Response: Physics.\n",
      "--------------------------------------------------\n",
      "Input: What is 2 + 2?\n",
      "Response: math\n",
      "--------------------------------------------------\n",
      "Input: Explain the Industrial Revolution.\n",
      "Response: History.\n",
      "--------------------------------------------------\n",
      "Input: What is a Turing machine?\n",
      "Response: comp sci\n",
      "--------------------------------------------------\n",
      "Input: What is the weather like today?\n",
      "Response: I'm sorry, but I can't provide real-time weather updates or information. Please check a reliable weather website or app for the current conditions in your area.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Parse the router result and run the appropriate chain\n",
    "def execute_chain(input_text):\n",
    "    # Get the destination and modified input from the router\n",
    "    router_result = router_chain.predict(input=input_text)\n",
    "    parsed_result = RouterOutputParser().parse(router_result)\n",
    "    destination = parsed_result[\"destination\"]\n",
    "    next_inputs = parsed_result[\"next_inputs\"]\n",
    "\n",
    "    # If destination is in destination_chains, run that chain\n",
    "    if destination in destination_chains:\n",
    "        response = destination_chains[destination].predict(input=next_inputs)\n",
    "    else:  # Fallback to default chain\n",
    "        response = default_chain.predict(input=next_inputs)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example Usage\n",
    "example_inputs = [\n",
    "    \"Tell me about Newton's laws of motion.\",\n",
    "    \"What is 2 + 2?\",\n",
    "    \"Explain the Industrial Revolution.\",\n",
    "    \"What is a Turing machine?\",\n",
    "    \"What is the weather like today?\"  # Should fallback to default\n",
    "]\n",
    "\n",
    "for input_text in example_inputs:\n",
    "    response = execute_chain(input_text)\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7c3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mystudyenv",
   "language": "python",
   "name": "mystudyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
